{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analytics\n",
    "###In which we analyze the Mood of the nation from inferences on SOTU by the POTUS\n",
    "###   (State Of The Union addresses by the President Of The US)\n",
    "\n",
    "#### Goal is to find interesting words in the speeches that reflect the times.\n",
    "\n",
    "####Am sure Lincoln didn't worry about WMDs and Iraq; neither did George Washington about inflation, Wall Street and Jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Spark Version 1.6.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.context import SparkContext\n",
    "print \"Running Spark Version %s\" % (sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.app.name=PySparkShell\n",
      "spark.files=file:/Users/ksankar/.ivy2/jars/com.databricks_spark-csv_2.10-1.3.0.jar,file:/Users/ksankar/.ivy2/jars/org.apache.commons_commons-csv-1.1.jar,file:/Users/ksankar/.ivy2/jars/com.univocity_univocity-parsers-1.5.1.jar\n",
      "spark.jars=file:/Users/ksankar/.ivy2/jars/com.databricks_spark-csv_2.10-1.3.0.jar,file:/Users/ksankar/.ivy2/jars/org.apache.commons_commons-csv-1.1.jar,file:/Users/ksankar/.ivy2/jars/com.univocity_univocity-parsers-1.5.1.jar\n",
      "spark.master=local[*]\n",
      "spark.submit.deployMode=client\n",
      "spark.submit.pyFiles=/Users/ksankar/.ivy2/jars/com.databricks_spark-csv_2.10-1.3.0.jar,/Users/ksankar/.ivy2/jars/org.apache.commons_commons-csv-1.1.jar,/Users/ksankar/.ivy2/jars/com.univocity_univocity-parsers-1.5.1.jar\n"
     ]
    }
   ],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "conf = SparkConf()\n",
    "print conf.toDebugString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###MapReduce in one line !\n",
    "###1. Split lines into words on space\n",
    "###2. Create key-value pair with key=word, value = 1\n",
    "###3. Sum value for each word (er ... key)\n",
    "###4. Then we get key-value RDD with key=word and value = number of times the word occured in a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4835"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"sotu/2009-2014-BO.txt\")\n",
    "word_count_bo = lines.flatMap(lambda x: x.split(' ')).\\\n",
    "    map(lambda x: (x.lower().rstrip().lstrip().rstrip(',').rstrip('.'), 1)).\\\n",
    "    reduceByKey(add)\n",
    "word_count_bo.count()\n",
    "#6658 without lower, 6299 with lower, rstrip,lstrip 4835"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5275"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"sotu/2009-2015-BO.txt\")\n",
    "word_count_bo_2015 = lines.flatMap(lambda x: x.split(' ')).\\\n",
    "    map(lambda x: (x.lower().rstrip().lstrip().rstrip(',').rstrip('.').replace(u\"\\u2019\", \"'\"), 1)).\\\n",
    "    reduceByKey(add)\n",
    "word_count_bo_2015.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#output = word_count_bo.collect()\n",
    "#for (word, count) in output:\n",
    "#    print \"%s: %i\" % (word, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4957"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"sotu/2001-2008-GWB.txt\")\n",
    "word_count_gwb = lines.flatMap(lambda x: x.split(' ')).map(lambda x: (x.lower().rstrip().lstrip().rstrip(',').rstrip('.'), 1)).reduceByKey(add)\n",
    "word_count_gwb.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5476"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"sotu/1994-2000-WJC.txt\")\n",
    "word_count_wjc = lines.flatMap(lambda x: x.split(' ')).map(lambda x: (x.lower().rstrip().lstrip().rstrip(',').rstrip('.'), 1)).reduceByKey(add)\n",
    "word_count_wjc.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3656"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"sotu/1961-1963-JFK.txt\")\n",
    "word_count_jfk = lines.flatMap(lambda x: x.split(' ')).map(lambda x: (x.lower().rstrip().lstrip().rstrip(',').rstrip('.'), 1)).reduceByKey(add)\n",
    "word_count_jfk.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5933"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"sotu/1934-1945-FDR.txt\")\n",
    "word_count_fdr = lines.flatMap(lambda x: x.split(' ')).map(lambda x: (x.lower().rstrip().lstrip().rstrip(',').rstrip('.'), 1)).reduceByKey(add)\n",
    "word_count_fdr.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4156"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"sotu/1861-1864-AL.txt\")\n",
    "word_count_al = lines.flatMap(lambda x: x.split(' ')).map(lambda x: (x.lower().rstrip().lstrip().rstrip(',').rstrip('.'), 1)).reduceByKey(add)\n",
    "word_count_al.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2951"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"sotu/1790-1796-GW.txt\")\n",
    "word_count_gw = lines.flatMap(lambda x: x.split(' ')).map(lambda x: (x.lower().rstrip().lstrip().rstrip(',').rstrip('.'), 1)).reduceByKey(add)\n",
    "word_count_gw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "common_words = [\"\",\"us\",\"has\",\"all\", \"they\", \"from\", \"who\",\"what\",\"on\",\"by\",\"more\",\"as\",\"not\",\"their\",\"can\",\n",
    "                             \"new\",\"it\",\"but\",\"be\",\"are\",\"--\",\"i\",\"have\",\"this\",\"will\",\"for\",\"with\",\"is\",\"that\",\"in\",\n",
    "                             \"our\",\"we\",\"a\",\"of\",\"to\",\"and\",\"the\",\"that's\",\"or\",\"make\",\"do\",\"you\",\"at\",\"it\\'s\",\"than\",\n",
    "                             \"if\",\"know\",\"last\",\"about\",\"no\",\"just\",\"now\",\"an\",\"because\",\"<p>we\",\"why\",\"we\\'ll\",\"how\",\n",
    "                             \"two\",\"also\",\"every\",\"come\",\"we've\",\"year\",\"over\",\"get\",\"take\",\"one\",\"them\",\"we\\'re\",\"need\",\n",
    "                             \"want\",\"when\",\"like\",\"most\",\"-\",\"been\",\"first\",\"where\",\"so\",\"these\",\"they\\'re\",\"good\",\"would\",\n",
    "                             \"there\",\"should\",\"-->\",\"<!--\",\"up\",\"i\\'m\",\"his\",\"their\",\"which\",\"may\",\"were\",\"such\",\"some\",\n",
    "                             \"those\",\"was\",\"here\",\"she\",\"he\",\"its\",\"her\",\"his\",\"don\\'t\",\"i\\'ve\",\"what\\'s\",\"didn\\'t\",\n",
    "                             \"shouldn\\'t\",\"(applause.)\",\"let\\'s\",\"doesn\\'t\",\"(laughter.)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_count_bo_1 = word_count_bo.sortBy(lambda x: x[1],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'the', 1812)\n",
      "(u'and', 1375)\n",
      "(u'to', 1351)\n",
      "(u'of', 1013)\n",
      "(u'a', 802)\n",
      "(u'that', 778)\n",
      "(u'we', 719)\n",
      "(u'our', 698)\n",
      "(u'in', 637)\n",
      "(u'', 585)\n"
     ]
    }
   ],
   "source": [
    "for x in word_count_bo_1.take(10):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_count_bo_clean = word_count_bo_1.filter(lambda x: x[0] not in common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4728"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_bo_clean.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'jobs', 148)\n",
      "(u'people', 144)\n",
      "(u'american', 133)\n",
      "(u'america', 131)\n",
      "(u'years', 116)\n",
      "(u'work', 108)\n",
      "(u'americans', 105)\n",
      "(u'time', 89)\n",
      "(u'energy', 87)\n",
      "(u'tonight', 84)\n",
      "(u'congress', 83)\n",
      "(u'country', 82)\n",
      "(u'help', 81)\n",
      "(u'economy', 79)\n",
      "(u'tax', 76)\n",
      "(u'right', 75)\n",
      "(u'businesses', 69)\n",
      "(u'my', 65)\n",
      "(u'world', 63)\n",
      "(u'government', 58)\n"
     ]
    }
   ],
   "source": [
    "for x in word_count_bo_clean.take(20):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_count_bo_2015_clean = word_count_bo_2015.filter(lambda x: x[0] not in common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'america', 207)\n",
      "(u'people', 158)\n",
      "(u'must', 153)\n",
      "(u'world', 131)\n",
      "(u'country', 108)\n",
      "(u'american', 104)\n",
      "(u'americans', 99)\n",
      "(u'congress', 99)\n",
      "(u'security', 98)\n",
      "(u'help', 90)\n",
      "(u'nation', 88)\n",
      "(u'terrorists', 83)\n",
      "(u'iraq', 80)\n",
      "(u'freedom', 79)\n",
      "(u'tonight', 76)\n"
     ]
    }
   ],
   "source": [
    "word_count_gwb_clean = word_count_gwb.filter(lambda x: x[0] not in common_words)\n",
    "word_count_gwb_clean.count()\n",
    "for x in word_count_gwb_clean.sortBy(lambda x: x[1],ascending=False).take(15):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'must', 289)\n",
      "(u'people', 266)\n",
      "(u'work', 194)\n",
      "(u'america', 188)\n",
      "(u'years', 176)\n",
      "(u'children', 153)\n",
      "(u'americans', 152)\n",
      "(u'congress', 147)\n",
      "(u'american', 136)\n",
      "(u'help', 117)\n",
      "(u'care', 116)\n",
      "(u'world', 108)\n",
      "(u'health', 102)\n",
      "(u'tonight', 98)\n",
      "(u'support', 93)\n"
     ]
    }
   ],
   "source": [
    "word_count_wjc_clean = word_count_wjc.filter(lambda x: x[0] not in common_words)\n",
    "word_count_wjc_clean.count()\n",
    "for x in word_count_wjc_clean.sortBy(lambda x: x[1],ascending=False).take(15):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'must', 289)\n",
      "(u'people', 266)\n",
      "(u'work', 194)\n",
      "(u'america', 188)\n",
      "(u'years', 176)\n",
      "(u'children', 153)\n",
      "(u'americans', 152)\n",
      "(u'congress', 147)\n",
      "(u'american', 136)\n",
      "(u'help', 117)\n",
      "(u'care', 116)\n",
      "(u'world', 108)\n",
      "(u'health', 102)\n",
      "(u'tonight', 98)\n",
      "(u'support', 93)\n"
     ]
    }
   ],
   "source": [
    "word_count_jfk_clean = word_count_wjc.filter(lambda x: x[0] not in common_words)\n",
    "word_count_jfk_clean.count()\n",
    "for x in word_count_jfk_clean.sortBy(lambda x: x[1],ascending=False).take(15):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'war', 238)\n",
      "(u'world', 167)\n",
      "(u'must', 161)\n",
      "(u'government', 154)\n",
      "(u'people', 141)\n",
      "(u'national', 130)\n",
      "(u'other', 124)\n",
      "(u'nation', 122)\n",
      "(u'nations', 111)\n",
      "(u'peace', 111)\n",
      "(u'united', 106)\n",
      "(u'congress', 105)\n",
      "(u'american', 97)\n",
      "(u'many', 94)\n",
      "(u'great', 91)\n"
     ]
    }
   ],
   "source": [
    "word_count_fdr_clean = word_count_fdr.filter(lambda x: x[0] not in common_words)\n",
    "word_count_fdr_clean.count()\n",
    "for x in word_count_fdr_clean.sortBy(lambda x: x[1],ascending=False).take(15):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'states', 148)\n",
      "(u'upon', 84)\n",
      "(u'united', 81)\n",
      "(u'any', 79)\n",
      "(u'congress', 77)\n",
      "(u'government', 73)\n",
      "(u'people', 70)\n",
      "(u'other', 69)\n",
      "(u'war', 64)\n",
      "(u'country', 62)\n",
      "(u'great', 61)\n",
      "(u'union', 53)\n",
      "(u'shall', 53)\n",
      "(u'time', 51)\n",
      "(u'under', 50)\n"
     ]
    }
   ],
   "source": [
    "word_count_al_clean = word_count_al.filter(lambda x: x[0] not in common_words)\n",
    "word_count_al_clean.count()\n",
    "for x in word_count_al_clean.sortBy(lambda x: x[1],ascending=False).take(15):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'states', 91)\n",
      "(u'united', 86)\n",
      "(u'public', 54)\n",
      "(u'your', 47)\n",
      "(u'government', 47)\n",
      "(u'made', 39)\n",
      "(u'upon', 38)\n",
      "(u'my', 37)\n",
      "(u'other', 37)\n",
      "(u'citizens', 33)\n",
      "(u'state', 32)\n",
      "(u'country', 31)\n",
      "(u'shall', 30)\n",
      "(u'peace', 30)\n",
      "(u'present', 28)\n"
     ]
    }
   ],
   "source": [
    "word_count_gw_clean = word_count_gw.filter(lambda x: x[0] not in common_words)\n",
    "word_count_gw_clean.count()\n",
    "for x in word_count_gw_clean.sortBy(lambda x: x[1],ascending=False).take(15):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Has Barack Obama changed in 2015 ?\n",
    "### As reflected in the SOTU 2009-2015 vs SOTU 2009-2014 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'childcare', 8)\n",
      "(u'rebekah', 7)\n",
      "(u'economics', 5)\n",
      "(u'believed', 4)\n",
      "(u'cuba', 4)\n",
      "(u'ben', 3)\n",
      "(u'(applause)', 3)\n",
      "(u'fears', 3)\n",
      "(u'twenty-first', 3)\n",
      "(u\"ben's\", 2)\n",
      "(u'speech', 2)\n",
      "(u'sights', 2)\n",
      "(u'keeper', 2)\n",
      "(u'misguided', 2)\n",
      "(u'constant', 2)\n"
     ]
    }
   ],
   "source": [
    "for x in word_count_bo_2015_clean.subtractByKey(word_count_bo_clean).sortBy(lambda x: x[1],ascending=False).take(15):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Coding Exercise\n",
    "## What mood was the country in 1790-1796 vs 2009-2015 ?\n",
    "### Hint:\n",
    "### 1. word_count_gw_clean = 1790-1796-GW.txt\n",
    "### 2. word_count_bo_2015_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'jobs', 148)\n",
      "(u'america', 131)\n",
      "(u'americans', 105)\n",
      "(u'tonight', 84)\n",
      "(u'help', 81)\n",
      "(u'businesses', 69)\n",
      "(u'health', 55)\n",
      "(u'back', 53)\n",
      "(u'job', 51)\n",
      "(u'reform', 51)\n",
      "(u'deficit', 48)\n",
      "(u'down', 47)\n",
      "(u'college', 40)\n",
      "(u'today', 40)\n",
      "(u\"can't\", 39)\n"
     ]
    }
   ],
   "source": [
    "for x in word_count_bo_clean.subtractByKey(word_count_gw_clean).sortBy(lambda x: x[1],ascending=False).take(15):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'present', 28)\n",
      "(u'measures', 26)\n",
      "(u'representatives:', 24)\n",
      "(u'provision', 24)\n",
      "(u'indians', 23)\n",
      "(u'militia', 20)\n",
      "(u'gentlemen', 19)\n",
      "(u'ought', 19)\n",
      "(u'object', 17)\n",
      "(u'however', 16)\n",
      "(u'satisfaction', 15)\n",
      "(u'establishment', 15)\n",
      "(u'due', 15)\n",
      "(u'objects', 15)\n",
      "(u'tribes', 14)\n"
     ]
    }
   ],
   "source": [
    "for x in word_count_gw_clean.subtractByKey(word_count_bo_clean).sortBy(lambda x: x[1],ascending=False).take(15):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Now it is easy to see Obama vs. FDR or WJC vs. AL ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'present', 39)\n",
      "(u'japanese', 36)\n",
      "(u'therefore', 31)\n",
      "(u'essential', 31)\n",
      "(u'enemy', 24)\n",
      "(u'1942', 22)\n",
      "(u'methods', 21)\n",
      "(u'adequate', 21)\n",
      "(u'principles', 20)\n",
      "(u'peoples', 20)\n",
      "(u'1933', 19)\n",
      "(u'however', 19)\n",
      "(u'objectives', 19)\n",
      "(u'agriculture', 18)\n",
      "(u'civilization', 18)\n"
     ]
    }
   ],
   "source": [
    "for x in word_count_fdr_clean.subtractByKey(word_count_bo_clean).sortBy(lambda x: x[1],ascending=False).take(15):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'energy', 87)\n",
      "(u'tonight', 84)\n",
      "(u'businesses', 69)\n",
      "(u'college', 40)\n",
      "(u'schools', 36)\n",
      "(u'students', 27)\n",
      "(u'oil', 26)\n",
      "(u'kids', 25)\n",
      "(u'republicans', 25)\n",
      "(u'innovation', 24)\n",
      "(u'gas', 23)\n",
      "(u'democrats', 23)\n",
      "(u'research', 22)\n",
      "(u'nuclear', 21)\n",
      "(u'technology', 20)\n"
     ]
    }
   ],
   "source": [
    "for x in word_count_bo_clean.subtractByKey(word_count_fdr_clean).sortBy(lambda x: x[1],ascending=False).take(15):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'oil', 26)\n",
      "(u'manufacturing', 19)\n",
      "(u'afghanistan', 18)\n",
      "(u'al', 15)\n",
      "(u'afghan', 15)\n",
      "(u'iran', 12)\n",
      "(u'solar', 12)\n",
      "(u'qaeda', 12)\n",
      "(u'code', 11)\n",
      "(u'rebuilding', 10)\n",
      "(u'worse', 10)\n",
      "(u'infrastructure', 10)\n",
      "(u'biden', 9)\n",
      "(u'breaks', 9)\n",
      "(u'high-speed', 8)\n"
     ]
    }
   ],
   "source": [
    "for x in word_count_bo_clean.subtractByKey(word_count_wjc_clean).sortBy(lambda x: x[1],ascending=False).take(15):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'banks', 22)\n",
      "(u'industry', 20)\n",
      "(u'trillion', 17)\n",
      "(u'middle-class', 13)\n",
      "(u'wage', 12)\n",
      "(u'class', 12)\n",
      "(u'forge', 11)\n",
      "(u'lay', 11)\n",
      "(u'lending', 11)\n",
      "(u'walk', 11)\n",
      "(u'helps', 10)\n",
      "(u'restore', 10)\n",
      "(u'minimum', 10)\n",
      "(u'high-tech', 9)\n",
      "(u'biden', 9)\n"
     ]
    }
   ],
   "source": [
    "for x in word_count_bo_clean.subtractByKey(word_count_gwb_clean).sortBy(lambda x: x[1],ascending=False).take(15):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'jobs', 148)\n",
      "(u'tonight', 84)\n",
      "(u'businesses', 69)\n",
      "(u'families', 56)\n",
      "(u'job', 51)\n",
      "(u'deficit', 48)\n",
      "(u'college', 40)\n",
      "(u'today', 40)\n",
      "(u\"can't\", 39)\n",
      "(u'schools', 36)\n",
      "(u'million', 36)\n",
      "(u'workers', 35)\n",
      "(u'clean', 35)\n",
      "(u'hard', 32)\n",
      "(u'budget', 30)\n"
     ]
    }
   ],
   "source": [
    "for x in word_count_bo_clean.subtractByKey(word_count_al_clean).sortBy(lambda x: x[1],ascending=False).take(15): #collect():\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'tonight', 98)\n",
      "(u'families', 82)\n",
      "(u'budget', 77)\n",
      "(u'challenge', 76)\n",
      "(u'parents', 70)\n",
      "(u'schools', 66)\n",
      "(u'jobs', 66)\n",
      "(u'child', 65)\n",
      "(u'million', 64)\n",
      "(u'today', 60)\n",
      "(u'crime', 60)\n",
      "(u'21st', 58)\n",
      "(u'college', 54)\n",
      "(u'thank', 47)\n",
      "(u'bill', 47)\n"
     ]
    }
   ],
   "source": [
    "for x in word_count_wjc_clean.subtractByKey(word_count_al_clean).sortBy(lambda x: x[1],ascending=False).take(15): #collect():\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'terrorists', 83)\n",
      "(u'iraq', 80)\n",
      "(u'tonight', 76)\n",
      "(u'terror', 63)\n",
      "(u'weapons', 56)\n",
      "(u'iraqi', 48)\n",
      "(u'jobs', 36)\n",
      "(u'workers', 36)\n",
      "(u'al', 36)\n",
      "(u'terrorist', 36)\n",
      "(u'afghanistan', 35)\n",
      "(u'qaeda', 32)\n",
      "(u'goal', 32)\n",
      "(u'nuclear', 32)\n",
      "(u'million', 31)\n"
     ]
    }
   ],
   "source": [
    "for x in word_count_gwb_clean.subtractByKey(word_count_al_clean).sortBy(lambda x: x[1],ascending=False).take(15): #collect():\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'persons', 30)\n",
      "(u'naval', 27)\n",
      "(u'present', 27)\n",
      "(u'emancipation', 25)\n",
      "(u'consideration', 22)\n",
      "(u'receipts', 22)\n",
      "(u'however', 21)\n",
      "(u'measures', 20)\n",
      "(u'slavery', 19)\n",
      "(u'proclamation', 17)\n",
      "(u'vessels', 17)\n",
      "(u'indian', 17)\n",
      "(u'believed', 16)\n",
      "(u'powers', 16)\n",
      "(u'actual', 16)\n"
     ]
    }
   ],
   "source": [
    "for x in word_count_al_clean.subtractByKey(word_count_bo_clean).sortBy(lambda x: x[1],ascending=False).take(15): #collect():\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'persons', 30)\n",
      "(u'navy', 28)\n",
      "(u'condition', 28)\n",
      "(u'naval', 27)\n",
      "(u'emancipation', 25)\n",
      "(u'thus', 23)\n",
      "(u'consideration', 22)\n",
      "(u'receipts', 22)\n",
      "(u'claims', 20)\n",
      "(u'interior', 18)\n",
      "(u'vessels', 17)\n",
      "(u'proclamation', 17)\n",
      "(u'powers', 16)\n",
      "(u'believed', 16)\n",
      "(u'actual', 16)\n"
     ]
    }
   ],
   "source": [
    "for x in word_count_al_clean.subtractByKey(word_count_wjc_clean).sortBy(lambda x: x[1],ascending=False).take(15): #collect():\n",
    "    print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That is All Folks !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
