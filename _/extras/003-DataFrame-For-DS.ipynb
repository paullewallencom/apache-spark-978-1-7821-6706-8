{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames For DataScientists\n",
    "1. SparkContext()\n",
    "1. Read/Write\n",
    "1. Convert\n",
    "1. Columns & Rows\n",
    "1. DataFrame : RDD-like Operations\n",
    "1. DataFrame : Action\n",
    "1. DataFrame : Scientific Functions\n",
    "1. DataFrame : Statistical Functions\n",
    "1. DataFrame : Aggregate Functions\n",
    "1. DataFrame : na\n",
    "1. DataFrame : Joins, Set Operations\n",
    "1. DataFrame : Tables & SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run @2015-12-17 21:23:50.063441-08:00\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from pytz import timezone\n",
    "print \"Last run @%s\" % (datetime.datetime.now(timezone('US/Pacific')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Spark Version 1.6.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.context import SparkContext\n",
    "print \"Running Spark Version %s\" % (sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.app.name=PySparkShell\n",
      "spark.files=file:/Users/ksankar/.ivy2/jars/com.databricks_spark-csv_2.10-1.3.0.jar,file:/Users/ksankar/.ivy2/jars/org.apache.commons_commons-csv-1.1.jar,file:/Users/ksankar/.ivy2/jars/com.univocity_univocity-parsers-1.5.1.jar\n",
      "spark.jars=file:/Users/ksankar/.ivy2/jars/com.databricks_spark-csv_2.10-1.3.0.jar,file:/Users/ksankar/.ivy2/jars/org.apache.commons_commons-csv-1.1.jar,file:/Users/ksankar/.ivy2/jars/com.univocity_univocity-parsers-1.5.1.jar\n",
      "spark.master=local[*]\n",
      "spark.submit.deployMode=client\n",
      "spark.submit.pyFiles=/Users/ksankar/.ivy2/jars/com.databricks_spark-csv_2.10-1.3.0.jar,/Users/ksankar/.ivy2/jars/org.apache.commons_commons-csv-1.1.jar,/Users/ksankar/.ivy2/jars/com.univocity_univocity-parsers-1.5.1.jar\n"
     ]
    }
   ],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "conf = SparkConf()\n",
    "print conf.toDebugString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sqlCxt = pyspark.sql.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read/Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o33.save.\n: java.lang.RuntimeException: path newcars.csv already exists.\n\tat scala.sys.package$.error(package.scala:27)\n\tat com.databricks.spark.csv.DefaultSource.createRelation(DefaultSource.scala:176)\n\tat org.apache.spark.sql.execution.datasources.ResolvedDataSource$.apply(ResolvedDataSource.scala:208)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:148)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:139)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ddb83e559a4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'com.databricks.spark.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'true'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spark-csv/cars.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoalesce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'com.databricks.spark.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'newcars.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ksankar/Downloads/spark-1.6.0/python/pyspark/sql/readwriter.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ksankar/Downloads/spark-1.6.0/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         return_value = get_return_value(\n\u001b[0;32m--> 813\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ksankar/Downloads/spark-1.6.0/python/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ksankar/Downloads/spark-1.6.0/python/lib/py4j-0.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    306\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    307\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o33.save.\n: java.lang.RuntimeException: path newcars.csv already exists.\n\tat scala.sys.package$.error(package.scala:27)\n\tat com.databricks.spark.csv.DefaultSource.createRelation(DefaultSource.scala:176)\n\tat org.apache.spark.sql.execution.datasources.ResolvedDataSource$.apply(ResolvedDataSource.scala:208)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:148)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:139)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "df = sqlContext.read.format('com.databricks.spark.csv').options(header='true').load('spark-csv/cars.csv')\n",
    "df.coalesce(1).select('year', 'model').write.format('com.databricks.spark.csv').save('newcars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+--------------------+-----+\n",
      "|year| make|model|             comment|blank|\n",
      "+----+-----+-----+--------------------+-----+\n",
      "|2012|Tesla|    S|          No comment|     |\n",
      "|1997| Ford| E350|Go get one now th...|     |\n",
      "|2015|Chevy| Volt|                null| null|\n",
      "+----+-----+-----+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_cars = sqlContext.read.format('com.databricks.spark.csv').options(header='true').load('car-data/car-milage.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mpg', 'double'),\n",
       " ('displacement', 'double'),\n",
       " ('hp', 'int'),\n",
       " ('torque', 'int'),\n",
       " ('CRatio', 'float'),\n",
       " ('RARatio', 'float'),\n",
       " ('CarbBarrells', 'int'),\n",
       " ('NoOfSpeed', 'int'),\n",
       " ('length', 'float'),\n",
       " ('width', 'float'),\n",
       " ('weight', 'int'),\n",
       " ('automatic', 'int')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cars_x = sqlContext.read.load('cars_1.parquet')\n",
    "df_cars_x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+\n",
      "|  mpg|displacement| hp|torque|CRatio|RARatio|CarbBarrells|NoOfSpeed|length|width|weight|automatic|\n",
      "+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+\n",
      "| 18.9|         350|165|   260|     8|   2.56|           4|        3| 200.3| 69.9|  3910|        1|\n",
      "|   17|         350|170|   275|   8.5|   2.56|           4|        3| 199.6| 72.9|  3860|        1|\n",
      "|   20|         250|105|   185|  8.25|   2.73|           1|        3| 196.7| 72.2|  3510|        1|\n",
      "|18.25|         351|143|   255|     8|      3|           2|        3| 199.9|   74|  3890|        1|\n",
      "|20.07|         225| 95|   170|   8.4|   2.76|           1|        3| 194.1| 71.8|  3365|        0|\n",
      "| 11.2|         440|215|   330|   8.2|   2.88|           4|        3| 184.5|   69|  4215|        1|\n",
      "|22.12|         231|110|   175|     8|   2.56|           2|        3| 179.3| 65.4|  3020|        1|\n",
      "|21.47|         262|110|   200|   8.5|   2.56|           2|        3| 179.3| 65.4|  3180|        1|\n",
      "| 34.7|        89.7| 70|    81|   8.2|    3.9|           2|        4| 155.7|   64|  1905|        0|\n",
      "| 30.4|        96.9| 75|    83|     9|    4.3|           2|        5| 165.2|   65|  2320|        0|\n",
      "| 16.5|         350|155|   250|   8.5|   3.08|           4|        3| 195.4| 74.4|  3885|        1|\n",
      "| 36.5|        85.3| 80|    83|   8.5|   3.89|           2|        4| 160.6| 62.2|  2009|        0|\n",
      "| 21.5|         171|109|   146|   8.2|   3.22|           2|        4| 170.4| 66.9|  2655|        0|\n",
      "| 19.7|         258|110|   195|     8|   3.08|           1|        3| 171.5|   77|  3375|        1|\n",
      "| 20.3|         140| 83|   109|   8.4|    3.4|           2|        4| 168.8| 69.4|  2700|        0|\n",
      "| 17.8|         302|129|   220|     8|      3|           2|        3| 199.9|   74|  3890|        1|\n",
      "|14.39|         500|190|   360|   8.5|   2.73|           4|        3| 224.1| 79.8|  5290|        1|\n",
      "|14.89|         440|215|   330|   8.2|   2.71|           4|        3|   231| 79.7|  5185|        1|\n",
      "| 17.8|         350|155|   250|   8.5|   3.08|           4|        3| 196.7| 72.2|  3910|        1|\n",
      "|16.41|         318|145|   255|   8.5|   2.45|           2|        3| 197.6|   71|  3660|        1|\n",
      "|23.54|         231|110|   175|     8|   2.56|           2|        3| 179.3| 65.4|  3050|        1|\n",
      "|21.47|         360|180|   290|   8.4|   2.45|           2|        3| 214.2| 76.3|  4250|        1|\n",
      "|16.59|         400|185|      |   7.6|   3.08|           4|        3|   196|   73|  3850|        1|\n",
      "| 31.9|        96.9| 75|    83|     9|    4.3|           2|        5| 165.2| 61.8|  2275|        0|\n",
      "| 29.4|         140| 86|      |     8|   2.92|           2|        4| 176.4| 65.4|  2150|        0|\n",
      "|13.27|         460|223|   366|     8|      3|           4|        3|   228| 79.8|  5430|        1|\n",
      "| 23.9|       133.6| 96|   120|   8.4|   3.91|           2|        5| 171.5| 63.4|  2535|        0|\n",
      "|19.73|         318|140|   255|   8.5|   2.71|           2|        3| 215.3| 76.3|  4370|        1|\n",
      "| 13.9|         351|148|   243|     8|   3.25|           2|        3| 215.5| 78.5|  4540|        1|\n",
      "|13.27|         351|148|   243|     8|   3.26|           2|        3| 216.1| 78.5|  4715|        1|\n",
      "|13.77|         360|195|   295|  8.25|   3.15|           4|        3| 209.3| 77.4|  4215|        1|\n",
      "| 16.5|         360|165|   255|   8.5|   2.73|           4|        3| 185.2|   69|  3660|        1|\n",
      "+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cars.show(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|summary|\n",
      "+-------+\n",
      "|  count|\n",
      "|   mean|\n",
      "| stddev|\n",
      "|    min|\n",
      "|    max|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cars.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+\n",
      "|summary|              mpg|                hp|\n",
      "+-------+-----------------+------------------+\n",
      "|  count|               32|                32|\n",
      "|   mean|        20.223125|           136.875|\n",
      "| stddev|6.318289089312789|44.980820285410395|\n",
      "|    min|             11.2|               105|\n",
      "|    max|             36.5|                96|\n",
      "+-------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cars.describe([\"mpg\",'hp']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "u'\"mpg\" is not a numeric column. Aggregation function can only be applied on a numeric column.;'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a0e8ae310b4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_cars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"automatic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ksankar/Downloads/spark-1.6.0/python/pyspark/sql/group.pyc\u001b[0m in \u001b[0;36m_api\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ksankar/Downloads/spark-1.6.0/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         return_value = get_return_value(\n\u001b[0;32m--> 813\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ksankar/Downloads/spark-1.6.0/python/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     49\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: u'\"mpg\" is not a numeric column. Aggregation function can only be applied on a numeric column.;'"
     ]
    }
   ],
   "source": [
    "df_cars.groupby(\"automatic\").avg(\"mpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cars.na.drop('any').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cars.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mpg', 'string'),\n",
       " ('displacement', 'string'),\n",
       " ('hp', 'string'),\n",
       " ('torque', 'string'),\n",
       " ('CRatio', 'string'),\n",
       " ('RARatio', 'string'),\n",
       " ('CarbBarrells', 'string'),\n",
       " ('NoOfSpeed', 'string'),\n",
       " ('length', 'string'),\n",
       " ('width', 'string'),\n",
       " ('weight', 'string'),\n",
       " ('automatic', 'string')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cars.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_2 = df_cars.select(df_cars.mpg.cast(\"double\").alias('mpg'),df_cars.torque.cast(\"double\").alias('torque'),\n",
    "                     df_cars.automatic.cast(\"integer\").alias('automatic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+\n",
      "|  mpg|torque|automatic|\n",
      "+-----+------+---------+\n",
      "| 18.9| 260.0|        1|\n",
      "| 17.0| 275.0|        1|\n",
      "| 20.0| 185.0|        1|\n",
      "|18.25| 255.0|        1|\n",
      "|20.07| 170.0|        0|\n",
      "| 11.2| 330.0|        1|\n",
      "|22.12| 175.0|        1|\n",
      "|21.47| 200.0|        1|\n",
      "| 34.7|  81.0|        0|\n",
      "| 30.4|  83.0|        0|\n",
      "| 16.5| 250.0|        1|\n",
      "| 36.5|  83.0|        0|\n",
      "| 21.5| 146.0|        0|\n",
      "| 19.7| 195.0|        1|\n",
      "| 20.3| 109.0|        0|\n",
      "| 17.8| 220.0|        1|\n",
      "|14.39| 360.0|        1|\n",
      "|14.89| 330.0|        1|\n",
      "| 17.8| 250.0|        1|\n",
      "|16.41| 255.0|        1|\n",
      "|23.54| 175.0|        1|\n",
      "|21.47| 290.0|        1|\n",
      "|16.59|  null|        1|\n",
      "| 31.9|  83.0|        0|\n",
      "| 29.4|  null|        0|\n",
      "|13.27| 366.0|        1|\n",
      "| 23.9| 120.0|        0|\n",
      "|19.73| 255.0|        1|\n",
      "| 13.9| 243.0|        1|\n",
      "|13.27| 243.0|        1|\n",
      "|13.77| 295.0|        1|\n",
      "| 16.5| 255.0|        1|\n",
      "+-----+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2.show(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mpg', 'double'), ('torque', 'double'), ('automatic', 'int')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------------+-------------------+\n",
      "|summary|              mpg|           torque|          automatic|\n",
      "+-------+-----------------+-----------------+-------------------+\n",
      "|  count|               32|               30|                 32|\n",
      "|   mean|        20.223125|            217.9|            0.71875|\n",
      "| stddev|6.318289089312789|83.06970483918289|0.45680340939917435|\n",
      "|    min|             11.2|             81.0|                  0|\n",
      "|    max|             36.5|            366.0|                  1|\n",
      "+-------+-----------------+-----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. DataFrame : Aggregate Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+-----------------+\n",
      "|automatic|          avg(mpg)|      avg(torque)|\n",
      "+---------+------------------+-----------------+\n",
      "|        0|27.630000000000003|          109.375|\n",
      "|        1|17.324782608695653|257.3636363636364|\n",
      "+---------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2.groupby(\"automatic\").avg(\"mpg\",\"torque\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "| avg(mpg)|avg(torque)|\n",
      "+---------+-----------+\n",
      "|20.223125|      217.9|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2.groupBy().avg(\"mpg\",\"torque\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      32|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2.agg({\"*\":\"count\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|min(mpg)|\n",
      "+--------+\n",
      "|    11.2|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "df_2.agg(F.min(df_2.mpg)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "| avg(mpg)|\n",
      "+---------+\n",
      "|20.223125|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "df_2.agg(F.mean(df_2.mpg)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|automatic|min(mpg)|\n",
      "+---------+--------+\n",
      "|        0|   20.07|\n",
      "|        1|    11.2|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gdf_2 = df_2.groupBy(\"automatic\")\n",
    "gdf_2.agg({'mpg':'min'}).collect()\n",
    "gdf_2.agg({'mpg':'min'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_cars_1 = df_cars.select(df_cars.mpg.cast(\"double\").alias('mpg'),\n",
    "                           df_cars.displacement.cast(\"double\").alias('displacement'),\n",
    "                           df_cars.hp.cast(\"integer\").alias('hp'),\n",
    "                           df_cars.torque.cast(\"integer\").alias('torque'),\n",
    "                           df_cars.CRatio.cast(\"float\").alias('CRatio'),\n",
    "                           df_cars.RARatio.cast(\"float\").alias('RARatio'),\n",
    "                           df_cars.CarbBarrells.cast(\"integer\").alias('CarbBarrells'),\n",
    "                           df_cars.NoOfSpeed.cast(\"integer\").alias('NoOfSpeed'),\n",
    "                           df_cars.length.cast(\"float\").alias('length'),\n",
    "                           df_cars.width.cast(\"float\").alias('width'),\n",
    "                           df_cars.weight.cast(\"integer\").alias('weight'),\n",
    "                           df_cars.automatic.cast(\"integer\").alias('automatic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|automatic|          avg(mpg)|\n",
      "+---------+------------------+\n",
      "|        0|27.630000000000003|\n",
      "|        1|17.324782608695653|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gdf_3 = df_cars_1.groupBy(\"automatic\")\n",
    "gdf_3.agg({'mpg':'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'avg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-2407b3220340>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_cars_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mpg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"torque\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ksankar/Downloads/spark-1.6.0/python/pyspark/sql/dataframe.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             raise AttributeError(\n\u001b[0;32m--> 839\u001b[0;31m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[1;32m    840\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'avg'"
     ]
    }
   ],
   "source": [
    "df_cars_1.avg(\"mpg\",\"torque\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "| avg(mpg)|avg(torque)|\n",
      "+---------+-----------+\n",
      "|20.223125|      217.9|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cars_1.groupBy().avg(\"mpg\",\"torque\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+-----------------+\n",
      "|automatic|          avg(mpg)|      avg(torque)|\n",
      "+---------+------------------+-----------------+\n",
      "|        0|27.630000000000003|          109.375|\n",
      "|        1|17.324782608695653|257.3636363636364|\n",
      "+---------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cars_1.groupby(\"automatic\").avg(\"mpg\",\"torque\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+-----------------+-----------------+------------------+\n",
      "|automatic|          avg(mpg)|      avg(torque)|          avg(hp)|       avg(weight)|\n",
      "+---------+------------------+-----------------+-----------------+------------------+\n",
      "|        0|27.630000000000003|          109.375|85.44444444444444|2434.8888888888887|\n",
      "|        1|17.324782608695653|257.3636363636364|            157.0| 4037.391304347826|\n",
      "+---------+------------------+-----------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cars_1.groupby(\"automatic\").avg(\"mpg\",\"torque\",\"hp\",\"weight\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mpg: double (nullable = true)\n",
      " |-- displacement: double (nullable = true)\n",
      " |-- hp: integer (nullable = true)\n",
      " |-- torque: integer (nullable = true)\n",
      " |-- CRatio: float (nullable = true)\n",
      " |-- RARatio: float (nullable = true)\n",
      " |-- CarbBarrells: integer (nullable = true)\n",
      " |-- NoOfSpeed: integer (nullable = true)\n",
      " |-- length: float (nullable = true)\n",
      " |-- width: float (nullable = true)\n",
      " |-- weight: integer (nullable = true)\n",
      " |-- automatic: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cars_1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+\n",
      "|  mpg|displacement| hp|torque|CRatio|RARatio|CarbBarrells|NoOfSpeed|length|width|weight|automatic|\n",
      "+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+\n",
      "| 18.9|       350.0|165|   260|   8.0|   2.56|           4|        3| 200.3| 69.9|  3910|        1|\n",
      "| 17.0|       350.0|170|   275|   8.5|   2.56|           4|        3| 199.6| 72.9|  3860|        1|\n",
      "| 20.0|       250.0|105|   185|  8.25|   2.73|           1|        3| 196.7| 72.2|  3510|        1|\n",
      "|18.25|       351.0|143|   255|   8.0|    3.0|           2|        3| 199.9| 74.0|  3890|        1|\n",
      "|20.07|       225.0| 95|   170|   8.4|   2.76|           1|        3| 194.1| 71.8|  3365|        0|\n",
      "+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cars_1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+-----------------+-------------------+------------------+-----------------+------------------+------------------+-----------------+-----------------+-------------------+\n",
      "|summary|              mpg|      displacement|                hp|           torque|             CRatio|           RARatio|     CarbBarrells|         NoOfSpeed|            length|            width|           weight|          automatic|\n",
      "+-------+-----------------+------------------+------------------+-----------------+-------------------+------------------+-----------------+------------------+------------------+-----------------+-----------------+-------------------+\n",
      "|  count|               32|                32|                32|               30|                 32|                32|               32|                32|                32|               32|               32|                 32|\n",
      "|   mean|        20.223125|         285.04375|           136.875|            217.9|  8.281249925494194|3.0553125217556953|          2.59375|           3.34375|191.95625019073486|71.28125071525574|        3586.6875|            0.71875|\n",
      "| stddev|6.318289089312789|117.24021367096235|44.980820285410395|83.06970483918289|0.30073833292040675|0.5123380437957931|1.073414058942533|0.6530017536902797| 20.54857328178095|5.603077410154348|947.9431872693228|0.45680340939917435|\n",
      "|    min|             11.2|              85.3|                70|               81|                7.6|              2.45|                1|                 3|             155.7|             61.8|             1905|                  0|\n",
      "|    max|             36.5|             500.0|               223|              366|                9.0|               4.3|                4|                 5|             231.0|             79.8|             5430|                  1|\n",
      "+-------+-----------------+------------------+------------------+-----------------+-------------------+------------------+-----------------+------------------+------------------+-----------------+-----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cars_1.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "| avg(mpg)|\n",
      "+---------+\n",
      "|20.223125|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cars_1.groupBy().agg({\"mpg\":\"mean\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+\n",
      "|  mpg|displacement| hp|torque|CRatio|RARatio|CarbBarrells|NoOfSpeed|length|width|weight|automatic|\n",
      "+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+\n",
      "| 18.9|       350.0|165|   260|   8.0|   2.56|           4|        3| 200.3| 69.9|  3910|        1|\n",
      "| 17.0|       350.0|170|   275|   8.5|   2.56|           4|        3| 199.6| 72.9|  3860|        1|\n",
      "| 20.0|       250.0|105|   185|  8.25|   2.73|           1|        3| 196.7| 72.2|  3510|        1|\n",
      "|18.25|       351.0|143|   255|   8.0|    3.0|           2|        3| 199.9| 74.0|  3890|        1|\n",
      "|20.07|       225.0| 95|   170|   8.4|   2.76|           1|        3| 194.1| 71.8|  3365|        0|\n",
      "| 11.2|       440.0|215|   330|   8.2|   2.88|           4|        3| 184.5| 69.0|  4215|        1|\n",
      "|22.12|       231.0|110|   175|   8.0|   2.56|           2|        3| 179.3| 65.4|  3020|        1|\n",
      "|21.47|       262.0|110|   200|   8.5|   2.56|           2|        3| 179.3| 65.4|  3180|        1|\n",
      "| 34.7|        89.7| 70|    81|   8.2|    3.9|           2|        4| 155.7| 64.0|  1905|        0|\n",
      "| 30.4|        96.9| 75|    83|   9.0|    4.3|           2|        5| 165.2| 65.0|  2320|        0|\n",
      "| 16.5|       350.0|155|   250|   8.5|   3.08|           4|        3| 195.4| 74.4|  3885|        1|\n",
      "| 36.5|        85.3| 80|    83|   8.5|   3.89|           2|        4| 160.6| 62.2|  2009|        0|\n",
      "| 21.5|       171.0|109|   146|   8.2|   3.22|           2|        4| 170.4| 66.9|  2655|        0|\n",
      "| 19.7|       258.0|110|   195|   8.0|   3.08|           1|        3| 171.5| 77.0|  3375|        1|\n",
      "| 20.3|       140.0| 83|   109|   8.4|    3.4|           2|        4| 168.8| 69.4|  2700|        0|\n",
      "| 17.8|       302.0|129|   220|   8.0|    3.0|           2|        3| 199.9| 74.0|  3890|        1|\n",
      "|14.39|       500.0|190|   360|   8.5|   2.73|           4|        3| 224.1| 79.8|  5290|        1|\n",
      "|14.89|       440.0|215|   330|   8.2|   2.71|           4|        3| 231.0| 79.7|  5185|        1|\n",
      "| 17.8|       350.0|155|   250|   8.5|   3.08|           4|        3| 196.7| 72.2|  3910|        1|\n",
      "|16.41|       318.0|145|   255|   8.5|   2.45|           2|        3| 197.6| 71.0|  3660|        1|\n",
      "|23.54|       231.0|110|   175|   8.0|   2.56|           2|        3| 179.3| 65.4|  3050|        1|\n",
      "|21.47|       360.0|180|   290|   8.4|   2.45|           2|        3| 214.2| 76.3|  4250|        1|\n",
      "|16.59|       400.0|185|  null|   7.6|   3.08|           4|        3| 196.0| 73.0|  3850|        1|\n",
      "| 31.9|        96.9| 75|    83|   9.0|    4.3|           2|        5| 165.2| 61.8|  2275|        0|\n",
      "| 29.4|       140.0| 86|  null|   8.0|   2.92|           2|        4| 176.4| 65.4|  2150|        0|\n",
      "|13.27|       460.0|223|   366|   8.0|    3.0|           4|        3| 228.0| 79.8|  5430|        1|\n",
      "| 23.9|       133.6| 96|   120|   8.4|   3.91|           2|        5| 171.5| 63.4|  2535|        0|\n",
      "|19.73|       318.0|140|   255|   8.5|   2.71|           2|        3| 215.3| 76.3|  4370|        1|\n",
      "| 13.9|       351.0|148|   243|   8.0|   3.25|           2|        3| 215.5| 78.5|  4540|        1|\n",
      "|13.27|       351.0|148|   243|   8.0|   3.26|           2|        3| 216.1| 78.5|  4715|        1|\n",
      "|13.77|       360.0|195|   295|  8.25|   3.15|           4|        3| 209.3| 77.4|  4215|        1|\n",
      "| 16.5|       360.0|165|   255|   8.5|   2.73|           4|        3| 185.2| 69.0|  3660|        1|\n",
      "+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cars_1.show(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. DataFrame : Statistical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8834003785623672"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cars_1.corr('hp','weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.43435769959911846"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cars_1.corr('RARatio','width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+---+---+\n",
      "|automatic_NoOfSpeed|  3|  4|  5|\n",
      "+-------------------+---+---+---+\n",
      "|                  1| 23|  0|  0|\n",
      "|                  0|  1|  5|  3|\n",
      "+-------------------+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cars_1.crosstab('automatic','NoOfSpeed').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---+---+---+\n",
      "|NoOfSpeed_CarbBarrells|  2|  1|  4|\n",
      "+----------------------+---+---+---+\n",
      "|                     5|  3|  0|  0|\n",
      "|                     4|  5|  0|  0|\n",
      "|                     3| 10|  3| 11|\n",
      "+----------------------+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cars_1.crosstab('NoOfSpeed','CarbBarrells').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---+---+---+\n",
      "|automatic_CarbBarrells|  1|  2|  4|\n",
      "+----------------------+---+---+---+\n",
      "|                     1|  2| 10| 11|\n",
      "|                     0|  1|  8|  0|\n",
      "+----------------------+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cars_1.crosstab('automatic','CarbBarrells').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. DataFrame : na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|isnull(torque)|\n",
      "+--------------+\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can see if a column has null values\n",
    "df_cars_1.select(df_cars_1.torque.isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+\n",
      "|  mpg|displacement| hp|torque|CRatio|RARatio|CarbBarrells|NoOfSpeed|length|width|weight|automatic|\n",
      "+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+\n",
      "|16.59|       400.0|185|  null|   7.6|   3.08|           4|        3| 196.0| 73.0|  3850|        1|\n",
      "| 29.4|       140.0| 86|  null|   8.0|   2.92|           2|        4| 176.4| 65.4|  2150|        0|\n",
      "+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can filter null and non null rows\n",
    "df_cars_1.filter(df_cars_1.torque.isNull()).show(40) # You can also use isNotNull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cars_1.na.drop().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+---+------+-----------------+------------------+------------+---------+------------------+------------------+------+---------+\n",
      "|  mpg|displacement| hp|torque|           CRatio|           RARatio|CarbBarrells|NoOfSpeed|            length|             width|weight|automatic|\n",
      "+-----+------------+---+------+-----------------+------------------+------------+---------+------------------+------------------+------+---------+\n",
      "| 18.9|       350.0|165|   260|              8.0| 2.559999942779541|           4|        3| 200.3000030517578|  69.9000015258789|  3910|        1|\n",
      "| 17.0|       350.0|170|   275|              8.5| 2.559999942779541|           4|        3|199.60000610351562|  72.9000015258789|  3860|        1|\n",
      "| 20.0|       250.0|105|   185|             8.25|2.7300000190734863|           1|        3| 196.6999969482422| 72.19999694824219|  3510|        1|\n",
      "|18.25|       351.0|143|   255|              8.0|               3.0|           2|        3|199.89999389648438|              74.0|  3890|        1|\n",
      "|20.07|       225.0| 95|   170|8.399999618530273| 2.759999990463257|           1|        3|194.10000610351562| 71.80000305175781|  3365|        0|\n",
      "| 11.2|       440.0|215|   330|8.199999809265137| 2.880000114440918|           4|        3|             184.5|              69.0|  4215|        1|\n",
      "|22.12|       231.0|110|   175|              8.0| 2.559999942779541|           2|        3| 179.3000030517578|  65.4000015258789|  3020|        1|\n",
      "|21.47|       262.0|110|   200|              8.5| 2.559999942779541|           2|        3| 179.3000030517578|  65.4000015258789|  3180|        1|\n",
      "| 34.7|        89.7| 70|    81|8.199999809265137|3.9000000953674316|           2|        4| 155.6999969482422|              64.0|  1905|        0|\n",
      "| 30.4|        96.9| 75|    83|              9.0| 4.300000190734863|           2|        5| 165.1999969482422|              65.0|  2320|        0|\n",
      "| 16.5|       350.0|155|   250|              8.5|3.0799999237060547|           4|        3|195.39999389648438|  74.4000015258789|  3885|        1|\n",
      "| 36.5|        85.3| 80|    83|              8.5| 3.890000104904175|           2|        4|160.60000610351562| 62.20000076293945|  2009|        0|\n",
      "| 21.5|       171.0|109|   146|8.199999809265137|3.2200000286102295|           2|        4|170.39999389648438|  66.9000015258789|  2655|        0|\n",
      "| 19.7|       258.0|110|   195|              8.0|3.0799999237060547|           1|        3|             171.5|              77.0|  3375|        1|\n",
      "| 20.3|       140.0| 83|   109|8.399999618530273|3.4000000953674316|           2|        4| 168.8000030517578|  69.4000015258789|  2700|        0|\n",
      "| 17.8|       302.0|129|   220|              8.0|               3.0|           2|        3|199.89999389648438|              74.0|  3890|        1|\n",
      "|14.39|       500.0|190|   360|              8.5|2.7300000190734863|           4|        3|224.10000610351562| 79.80000305175781|  5290|        1|\n",
      "|14.89|       440.0|215|   330|8.199999809265137|2.7100000381469727|           4|        3|             231.0| 79.69999694824219|  5185|        1|\n",
      "| 17.8|       350.0|155|   250|              8.5|3.0799999237060547|           4|        3| 196.6999969482422| 72.19999694824219|  3910|        1|\n",
      "|16.41|       318.0|145|   255|              8.5| 2.450000047683716|           2|        3|197.60000610351562|              71.0|  3660|        1|\n",
      "|23.54|       231.0|110|   175|              8.0| 2.559999942779541|           2|        3| 179.3000030517578|  65.4000015258789|  3050|        1|\n",
      "|21.47|       360.0|180|   290|8.399999618530273| 2.450000047683716|           2|        3| 214.1999969482422| 76.30000305175781|  4250|        1|\n",
      "|16.59|       400.0|185|  9999|7.599999904632568|3.0799999237060547|           4|        3|             196.0|              73.0|  3850|        1|\n",
      "| 31.9|        96.9| 75|    83|              9.0| 4.300000190734863|           2|        5| 165.1999969482422| 61.79999923706055|  2275|        0|\n",
      "| 29.4|       140.0| 86|  9999|              8.0|2.9200000762939453|           2|        4|176.39999389648438|  65.4000015258789|  2150|        0|\n",
      "|13.27|       460.0|223|   366|              8.0|               3.0|           4|        3|             228.0| 79.80000305175781|  5430|        1|\n",
      "| 23.9|       133.6| 96|   120|8.399999618530273|3.9100000858306885|           2|        5|             171.5|63.400001525878906|  2535|        0|\n",
      "|19.73|       318.0|140|   255|              8.5|2.7100000381469727|           2|        3| 215.3000030517578| 76.30000305175781|  4370|        1|\n",
      "| 13.9|       351.0|148|   243|              8.0|              3.25|           2|        3|             215.5|              78.5|  4540|        1|\n",
      "|13.27|       351.0|148|   243|              8.0| 3.259999990463257|           2|        3|216.10000610351562|              78.5|  4715|        1|\n",
      "|13.77|       360.0|195|   295|             8.25|3.1500000953674316|           4|        3| 209.3000030517578|  77.4000015258789|  4215|        1|\n",
      "| 16.5|       360.0|165|   255|              8.5|2.7300000190734863|           4|        3| 185.1999969482422|              69.0|  3660|        1|\n",
      "+-----+------------+---+------+-----------------+------------------+------------+---------+------------------+------------------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cars_1.fillna(9999).show(50)\n",
    "# This is not what we will do normally. Just to show the effect of fillna\n",
    "# you can use df_cars_1.na.fill(9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| hp|hpCode|\n",
      "+---+------+\n",
      "|165|     2|\n",
      "|170|     2|\n",
      "|105|     2|\n",
      "|143|     2|\n",
      "| 95|     1|\n",
      "|215|     3|\n",
      "|110|     2|\n",
      "|110|     2|\n",
      "| 70|     1|\n",
      "| 75|     1|\n",
      "|155|     2|\n",
      "| 80|     1|\n",
      "|109|     2|\n",
      "|110|     2|\n",
      "| 83|     1|\n",
      "|129|     2|\n",
      "|190|     2|\n",
      "|215|     3|\n",
      "|155|     2|\n",
      "|145|     2|\n",
      "|110|     2|\n",
      "|180|     2|\n",
      "|185|     2|\n",
      "| 75|     1|\n",
      "| 86|     1|\n",
      "|223|     3|\n",
      "| 96|     1|\n",
      "|140|     2|\n",
      "|148|     2|\n",
      "|148|     2|\n",
      "|195|     2|\n",
      "|165|     2|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let us try the interesting when syntax on the HP column\n",
    "# 0-100=1,101-200=2,201-300=3,others=4\n",
    "df_cars_1.select(df_cars_1.hp, F.when(df_cars_1.hp <= 100, 1).when(df_cars_1.hp <= 200, 2)\n",
    "                 .when(df_cars_1.hp <= 300, 3).otherwise(4).alias(\"hpCode\")).show(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mpg', 'double'),\n",
       " ('displacement', 'double'),\n",
       " ('hp', 'int'),\n",
       " ('torque', 'int'),\n",
       " ('CRatio', 'float'),\n",
       " ('RARatio', 'float'),\n",
       " ('CarbBarrells', 'int'),\n",
       " ('NoOfSpeed', 'int'),\n",
       " ('length', 'float'),\n",
       " ('width', 'float'),\n",
       " ('weight', 'int'),\n",
       " ('automatic', 'int')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cars_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|CarbBarrells|count|\n",
      "+------------+-----+\n",
      "|           1|    3|\n",
      "|           2|   18|\n",
      "|           4|   11|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cars_1.groupBy('CarbBarrells').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "u'path file:/Users/ksankar/global-bd-conf/cars_1.parquet already exists.;'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-cc10f3e861cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# java.lang.RuntimeException: path file:.. /cars_1.parquet already exists.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_cars_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cars_1.parquet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ksankar/Downloads/spark-1.6.0/python/pyspark/sql/readwriter.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ksankar/Downloads/spark-1.6.0/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         return_value = get_return_value(\n\u001b[0;32m--> 813\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ksankar/Downloads/spark-1.6.0/python/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     49\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: u'path file:/Users/ksankar/global-bd-conf/cars_1.parquet already exists.;'"
     ]
    }
   ],
   "source": [
    "# If file exists, will give error\n",
    "# java.lang.RuntimeException: path file:.. /cars_1.parquet already exists.\n",
    "#\n",
    "df_cars_1.repartition(1).write.save(\"cars_1.parquet\", format=\"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# No error even if the file exists\n",
    "df_cars_1.repartition(1).write.mode(\"overwrite\").format(\"parquet\").save(\"cars_1.parquet\")\n",
    "# Use repartition if you want all data in one (or more) file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Appends to existing file\n",
    "df_cars_1.repartition(1).write.mode(\"append\").format(\"parquet\").save(\"cars_1_a.parquet\")\n",
    "# Even with repartition, you will see more files as it is append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksankar/Downloads/spark-1.6.0/python/pyspark/sql/context.py:538: UserWarning: load is deprecated. Use read.load() instead.\n",
      "  warnings.warn(\"load is deprecated. Use read.load() instead.\")\n"
     ]
    }
   ],
   "source": [
    "df_append = sqlContext.load(\"cars_1_a.parquet\")\n",
    "# sqlContext.load is deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_append.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eventhough parquet is the default format, explicit format(\"parquet\") is clearer\n",
    "df_append = sqlContext.read.format(\"parquet\").load(\"cars_1_a.parquet\")\n",
    "df_append.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for reading parquet files read.parquet is more elegant\n",
    "df_append = sqlContext.read.parquet(\"cars_1_a.parquet\")\n",
    "df_append.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let us read another file\n",
    "df_orders = sqlContext.read.format('com.databricks.spark.csv').options(header='true').load('NW/NW-Orders.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(OrderID=u'10248', CustomerID=u'VINET', EmpliyeeID=u'5', OrderDate=u'7/2/96', ShipCuntry=u'France')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('OrderID', 'string'),\n",
       " ('CustomerID', 'string'),\n",
       " ('EmpliyeeID', 'string'),\n",
       " ('OrderDate', 'string'),\n",
       " ('ShipCuntry', 'string')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, IntegerType,DateType\n",
    "getYear = F.udf(lambda s: s[-2:], StringType()) #IntegerType())\n",
    "from datetime import datetime\n",
    "convertToDate = F.udf(lambda s: datetime.strptime(s, '%m/%d/%y'),DateType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# You could register the function for sql as follows. We won't use this here\n",
    "sqlContext.registerFunction(\"getYear\", lambda s: s[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+---------+-----------+-----------------------------+\n",
      "|OrderID|CustomerID|EmpliyeeID|OrderDate|ShipCountry|PythonUDF#<lambda>(OrderDate)|\n",
      "+-------+----------+----------+---------+-----------+-----------------------------+\n",
      "|  10248|     VINET|         5|   7/2/96|     France|                           96|\n",
      "|  10249|     TOMSP|         6|   7/3/96|    Germany|                           96|\n",
      "|  10250|     HANAR|         4|   7/6/96|     Brazil|                           96|\n",
      "|  10251|     VICTE|         3|   7/6/96|     France|                           96|\n",
      "|  10252|     SUPRD|         4|   7/7/96|    Belgium|                           96|\n",
      "|  10253|     HANAR|         3|   7/8/96|     Brazil|                           96|\n",
      "|  10254|     CHOPS|         5|   7/9/96|Switzerland|                           96|\n",
      "|  10255|     RICSU|         9|  7/10/96|Switzerland|                           96|\n",
      "|  10256|     WELLI|         3|  7/13/96|     Brazil|                           96|\n",
      "|  10257|     HILAA|         4|  7/14/96|  Venezuela|                           96|\n",
      "|  10258|     ERNSH|         1|  7/15/96|    Austria|                           96|\n",
      "|  10259|     CENTC|         4|  7/16/96|     Mexico|                           96|\n",
      "|  10260|     OTTIK|         4|  7/17/96|    Germany|                           96|\n",
      "|  10261|     QUEDE|         4|  7/17/96|     Brazil|                           96|\n",
      "|  10262|     RATTC|         8|  7/20/96|        USA|                           96|\n",
      "|  10263|     ERNSH|         9|  7/21/96|    Austria|                           96|\n",
      "|  10264|     FOLKO|         6|  7/22/96|     Sweden|                           96|\n",
      "|  10265|     BLONP|         2|  7/23/96|     France|                           96|\n",
      "|  10266|     WARTH|         3|  7/24/96|    Finland|                           96|\n",
      "|  10267|     FRANK|         4|  7/27/96|    Germany|                           96|\n",
      "+-------+----------+----------+---------+-----------+-----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let us add an year column\n",
    "df_orders.select(df_orders['OrderID'], \n",
    "                 df_orders['CustomerID'],\n",
    "                 df_orders['EmpliyeeID'], \n",
    "                 df_orders['OrderDate'],\n",
    "                 df_orders['ShipCuntry'].alias('ShipCountry'),\n",
    "                 getYear(df_orders['OrderDate'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# let us add an year column\n",
    "# Need alias\n",
    "df_orders_1 = df_orders.select(df_orders['OrderID'], \n",
    "                 df_orders['CustomerID'],\n",
    "                 df_orders['EmpliyeeID'], \n",
    "                 convertToDate(df_orders['OrderDate']).alias('OrderDate'),\n",
    "                 df_orders['ShipCuntry'].alias('ShipCountry'),\n",
    "                 getYear(df_orders['OrderDate']).alias('Year'))\n",
    "# df_orders_1 = df_orders_x.withColumn('Year',getYear(df_orders_x['OrderDate'])) # doesn't work. Gives error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+----------+-----------+----+\n",
      "|OrderID|CustomerID|EmpliyeeID| OrderDate|ShipCountry|Year|\n",
      "+-------+----------+----------+----------+-----------+----+\n",
      "|  10248|     VINET|         5|1996-07-02|     France|  96|\n",
      "+-------+----------+----------+----------+-----------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_orders_1.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('OrderID', 'string'),\n",
       " ('CustomerID', 'string'),\n",
       " ('EmpliyeeID', 'string'),\n",
       " ('OrderDate', 'date'),\n",
       " ('ShipCountry', 'string'),\n",
       " ('Year', 'string')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+----------+-----------+----+\n",
      "|OrderID|CustomerID|EmpliyeeID| OrderDate|ShipCountry|Year|\n",
      "+-------+----------+----------+----------+-----------+----+\n",
      "|  10248|     VINET|         5|1996-07-02|     France|  96|\n",
      "|  10249|     TOMSP|         6|1996-07-03|    Germany|  96|\n",
      "|  10250|     HANAR|         4|1996-07-06|     Brazil|  96|\n",
      "|  10251|     VICTE|         3|1996-07-06|     France|  96|\n",
      "|  10252|     SUPRD|         4|1996-07-07|    Belgium|  96|\n",
      "|  10253|     HANAR|         3|1996-07-08|     Brazil|  96|\n",
      "|  10254|     CHOPS|         5|1996-07-09|Switzerland|  96|\n",
      "|  10255|     RICSU|         9|1996-07-10|Switzerland|  96|\n",
      "|  10256|     WELLI|         3|1996-07-13|     Brazil|  96|\n",
      "|  10257|     HILAA|         4|1996-07-14|  Venezuela|  96|\n",
      "|  10258|     ERNSH|         1|1996-07-15|    Austria|  96|\n",
      "|  10259|     CENTC|         4|1996-07-16|     Mexico|  96|\n",
      "|  10260|     OTTIK|         4|1996-07-17|    Germany|  96|\n",
      "|  10261|     QUEDE|         4|1996-07-17|     Brazil|  96|\n",
      "|  10262|     RATTC|         8|1996-07-20|        USA|  96|\n",
      "|  10263|     ERNSH|         9|1996-07-21|    Austria|  96|\n",
      "|  10264|     FOLKO|         6|1996-07-22|     Sweden|  96|\n",
      "|  10265|     BLONP|         2|1996-07-23|     France|  96|\n",
      "|  10266|     WARTH|         3|1996-07-24|    Finland|  96|\n",
      "|  10267|     FRANK|         4|1996-07-27|    Germany|  96|\n",
      "+-------+----------+----------+----------+-----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_orders_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+----------+-----------+----+\n",
      "|OrderID|CustomerID|EmpliyeeID| OrderDate|ShipCountry|Year|\n",
      "+-------+----------+----------+----------+-----------+----+\n",
      "|  10248|     VINET|         5|1996-07-02|     France|  96|\n",
      "|  10251|     VICTE|         3|1996-07-06|     France|  96|\n",
      "|  10265|     BLONP|         2|1996-07-23|     France|  96|\n",
      "|  10274|     VINET|         6|1996-08-04|     France|  96|\n",
      "|  10295|     VINET|         2|1996-08-31|     France|  96|\n",
      "|  10297|     BLONP|         5|1996-09-02|     France|  96|\n",
      "|  10311|     DUMON|         1|1996-09-18|     France|  96|\n",
      "|  10331|     BONAP|         9|1996-10-14|     France|  96|\n",
      "|  10334|     VICTE|         8|1996-10-19|     France|  96|\n",
      "|  10340|     BONAP|         1|1996-10-27|     France|  96|\n",
      "|  10350|     LAMAI|         6|1996-11-09|     France|  96|\n",
      "|  10358|     LAMAI|         5|1996-11-18|     France|  96|\n",
      "|  10360|     BLONP|         4|1996-11-20|     France|  96|\n",
      "|  10362|     BONAP|         3|1996-11-23|     France|  96|\n",
      "|  10371|     LAMAI|         1|1996-12-01|     France|  96|\n",
      "|  10408|     FOLIG|         8|1997-01-06|     France|  97|\n",
      "|  10413|     LAMAI|         3|1997-01-12|     France|  97|\n",
      "|  10425|     LAMAI|         6|1997-01-22|     France|  97|\n",
      "|  10436|     BLONP|         3|1997-02-03|     France|  97|\n",
      "|  10449|     BLONP|         3|1997-02-16|     France|  97|\n",
      "+-------+----------+----------+----------+-----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_orders_1.where(df_orders_1['ShipCountry'] == 'France').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----+\n",
      "|CustomerID|Year|count|\n",
      "+----------+----+-----+\n",
      "|     SAVEA|  97|   17|\n",
      "|     ERNSH|  97|   14|\n",
      "|     QUICK|  97|   14|\n",
      "|     SAVEA|  98|   11|\n",
      "|     BERGS|  97|   10|\n",
      "|     WARTH|  97|   10|\n",
      "|     MEREP|  97|   10|\n",
      "|     HILAA|  97|   10|\n",
      "|     HUNGO|  97|   10|\n",
      "|     ERNSH|  98|    9|\n",
      "|     FOLKO|  98|    9|\n",
      "|     KOENE|  97|    8|\n",
      "|     BOTTM|  98|    8|\n",
      "|     WHITC|  97|    8|\n",
      "|     LEHMS|  97|    8|\n",
      "|     BONAP|  97|    8|\n",
      "|     FRANK|  97|    8|\n",
      "|     QUICK|  98|    8|\n",
      "|     LAMAI|  97|    8|\n",
      "|     RATTC|  96|    7|\n",
      "+----------+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_orders_1.groupBy(\"CustomerID\",\"Year\").count().orderBy('count',ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----+\n",
      "|CustomerID|Year|count|\n",
      "+----------+----+-----+\n",
      "|     SAVEA|  97|   17|\n",
      "|     ERNSH|  97|   14|\n",
      "|     QUICK|  97|   14|\n",
      "|     SAVEA|  98|   11|\n",
      "|     HUNGO|  97|   10|\n",
      "|     MEREP|  97|   10|\n",
      "|     WARTH|  97|   10|\n",
      "|     BERGS|  97|   10|\n",
      "|     HILAA|  97|   10|\n",
      "|     FOLKO|  98|    9|\n",
      "|     ERNSH|  98|    9|\n",
      "|     LEHMS|  97|    8|\n",
      "|     WHITC|  97|    8|\n",
      "|     QUICK|  98|    8|\n",
      "|     BOTTM|  98|    8|\n",
      "|     BONAP|  97|    8|\n",
      "|     FRANK|  97|    8|\n",
      "|     LAMAI|  97|    8|\n",
      "|     KOENE|  97|    8|\n",
      "|     FOLKO|  97|    7|\n",
      "+----------+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_orders_1.groupBy(\"CustomerID\",\"Year\").count().orderBy('count',ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# save by partition (year)\n",
    "df_orders_1.write.mode(\"overwrite\").partitionBy(\"Year\").format(\"parquet\").save(\"orders_1.parquet\")\n",
    "# load defaults to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "Relation[OrderID#2075,CustomerID#2076,EmpliyeeID#2077,OrderDate#2078,ShipCountry#2079,Year#2080] ParquetRelation\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "OrderID: string, CustomerID: string, EmpliyeeID: string, OrderDate: date, ShipCountry: string, Year: int\n",
      "Relation[OrderID#2075,CustomerID#2076,EmpliyeeID#2077,OrderDate#2078,ShipCountry#2079,Year#2080] ParquetRelation\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Relation[OrderID#2075,CustomerID#2076,EmpliyeeID#2077,OrderDate#2078,ShipCountry#2079,Year#2080] ParquetRelation\n",
      "\n",
      "== Physical Plan ==\n",
      "Scan ParquetRelation[OrderID#2075,CustomerID#2076,EmpliyeeID#2077,OrderDate#2078,ShipCountry#2079,Year#2080] InputPaths: file:/Users/ksankar/global-bd-conf/orders_1.parquet\n",
      "== Parsed Logical Plan ==\n",
      "'Filter (Year#2080 = 96)\n",
      "+- Relation[OrderID#2075,CustomerID#2076,EmpliyeeID#2077,OrderDate#2078,ShipCountry#2079,Year#2080] ParquetRelation\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "OrderID: string, CustomerID: string, EmpliyeeID: string, OrderDate: date, ShipCountry: string, Year: int\n",
      "Filter (cast(Year#2080 as double) = cast(96 as double))\n",
      "+- Relation[OrderID#2075,CustomerID#2076,EmpliyeeID#2077,OrderDate#2078,ShipCountry#2079,Year#2080] ParquetRelation\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Filter (cast(Year#2080 as double) = 96.0)\n",
      "+- Relation[OrderID#2075,CustomerID#2076,EmpliyeeID#2077,OrderDate#2078,ShipCountry#2079,Year#2080] ParquetRelation\n",
      "\n",
      "== Physical Plan ==\n",
      "Scan ParquetRelation[OrderID#2075,CustomerID#2076,EmpliyeeID#2077,OrderDate#2078,ShipCountry#2079,Year#2080] InputPaths: file:/Users/ksankar/global-bd-conf/orders_1.parquet\n"
     ]
    }
   ],
   "source": [
    "df_orders_2 = sqlContext.read.parquet(\"orders_1.parquet\")\n",
    "df_orders_2.explain(True)\n",
    "df_orders_3 = df_orders_2.filter(df_orders_2.Year=='96')\n",
    "df_orders_3.explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders_3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Filter (Year#2080 = 96)\n",
      "+- Relation[OrderID#2075,CustomerID#2076,EmpliyeeID#2077,OrderDate#2078,ShipCountry#2079,Year#2080] ParquetRelation\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "OrderID: string, CustomerID: string, EmpliyeeID: string, OrderDate: date, ShipCountry: string, Year: int\n",
      "Filter (cast(Year#2080 as double) = cast(96 as double))\n",
      "+- Relation[OrderID#2075,CustomerID#2076,EmpliyeeID#2077,OrderDate#2078,ShipCountry#2079,Year#2080] ParquetRelation\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Filter (cast(Year#2080 as double) = 96.0)\n",
      "+- Relation[OrderID#2075,CustomerID#2076,EmpliyeeID#2077,OrderDate#2078,ShipCountry#2079,Year#2080] ParquetRelation\n",
      "\n",
      "== Physical Plan ==\n",
      "Scan ParquetRelation[OrderID#2075,CustomerID#2076,EmpliyeeID#2077,OrderDate#2078,ShipCountry#2079,Year#2080] InputPaths: file:/Users/ksankar/global-bd-conf/orders_1.parquet\n"
     ]
    }
   ],
   "source": [
    "df_orders_3.explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "830"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders_2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- OrderID: string (nullable = true)\n",
      " |-- CustomerID: string (nullable = true)\n",
      " |-- EmpliyeeID: string (nullable = true)\n",
      " |-- OrderDate: date (nullable = true)\n",
      " |-- ShipCountry: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_orders_1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. DataFrame : Scientific Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksankar/Downloads/spark-1.6.0/python/pyspark/sql/context.py:262: UserWarning: Using RDD of dict to inferSchema is deprecated. Use pyspark.sql.Row instead\n",
      "  warnings.warn(\"Using RDD of dict to inferSchema is deprecated. \"\n"
     ]
    }
   ],
   "source": [
    "# import pyspark.sql.Row\n",
    "df = sc.parallelize([10,100,1000]).map(lambda x: {\"num\":x}).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| num|\n",
      "+----+\n",
      "|  10|\n",
      "| 100|\n",
      "|1000|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|         LOG(num)|\n",
      "+-----------------+\n",
      "|2.302585092994046|\n",
      "|4.605170185988092|\n",
      "|6.907755278982137|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "df.select(F.log(df.num)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|LOG10(num)|\n",
      "+----------+\n",
      "|       1.0|\n",
      "|       2.0|\n",
      "|       3.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.log10(df.num)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = sc.parallelize([0,10,100,1000]).map(lambda x: {\"num\":x}).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| num|\n",
      "+----+\n",
      "|   0|\n",
      "|  10|\n",
      "| 100|\n",
      "|1000|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|         LOG(num)|\n",
      "+-----------------+\n",
      "|             null|\n",
      "|2.302585092994046|\n",
      "|4.605170185988092|\n",
      "|6.907755278982137|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.log(df.num)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|        LOG1P(num)|\n",
      "+------------------+\n",
      "|               0.0|\n",
      "|2.3978952727983707|\n",
      "|  4.61512051684126|\n",
      "|  6.90875477931522|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.log1p(df.num)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|CarbBarrells|         SQRT(mpg)|\n",
      "+------------+------------------+\n",
      "|           4| 4.347413023856832|\n",
      "|           4| 4.123105625617661|\n",
      "|           1|  4.47213595499958|\n",
      "|           2| 4.272001872658765|\n",
      "|           1| 4.479955356920423|\n",
      "|           4|3.3466401061363023|\n",
      "|           2| 4.703190406521939|\n",
      "|           2| 4.633573135281238|\n",
      "|           2| 5.890670590009257|\n",
      "|           2| 5.513619500836088|\n",
      "|           4|  4.06201920231798|\n",
      "|           2| 6.041522986797286|\n",
      "|           2| 4.636809247747852|\n",
      "|           1|  4.43846820423443|\n",
      "|           2| 4.505552130427524|\n",
      "|           2| 4.219004621945797|\n",
      "|           4|3.7934153476781316|\n",
      "|           4|3.8587562763149474|\n",
      "|           4| 4.219004621945797|\n",
      "|           2| 4.050925820105819|\n",
      "+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cars_1.select(df_cars_1['CarbBarrells'], F.sqrt(df_cars_1['mpg'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = sc.parallelize([(3,4),(5,12),(7,24),(9,40),(11,60),(13,84)]).map(lambda x: {\"a\":x[0],\"b\":x[1]}).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|  a|  b|\n",
      "+---+---+\n",
      "|  3|  4|\n",
      "|  5| 12|\n",
      "|  7| 24|\n",
      "|  9| 40|\n",
      "| 11| 60|\n",
      "| 13| 84|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-----+\n",
      "|  a|  b|hypot|\n",
      "+---+---+-----+\n",
      "|  3|  4|  5.0|\n",
      "|  5| 12| 13.0|\n",
      "|  7| 24| 25.0|\n",
      "|  9| 40| 41.0|\n",
      "| 11| 60| 61.0|\n",
      "| 13| 84| 85.0|\n",
      "+---+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df['a'],df['b'],F.hypot(df['a'],df['b']).alias('hypot')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. DataFrame : Joins, Set Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_a = sc.parallelize( [{\"X1\":\"A\",\"X2\":1},{\"X1\":\"B\",\"X2\":2},{\"X1\":\"C\",\"X2\":3}] ).toDF()\n",
    "df_b = sc.parallelize( [{\"X1\":\"A\",\"X3\":True},{\"X1\":\"B\",\"X3\":False},{\"X1\":\"D\",\"X3\":True}] ).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| X1| X2|\n",
      "+---+---+\n",
      "|  A|  1|\n",
      "|  B|  2|\n",
      "|  C|  3|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| X1|   X3|\n",
      "+---+-----+\n",
      "|  A| true|\n",
      "|  B|false|\n",
      "|  D| true|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_b.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---+-----+\n",
      "|X1-a|X1-b| X2|   X3|\n",
      "+----+----+---+-----+\n",
      "|   A|   A|  1| true|\n",
      "|   B|   B|  2|false|\n",
      "+----+----+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_a.join(df_b, df_a['X1'] == df_b['X1'], 'inner')\\\n",
    ".select(df_a['X1'].alias('X1-a'),df_b['X1'].alias('X1-b'),'X2','X3').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+-----+\n",
      "|X1-a|X1-b|  X2|   X3|\n",
      "+----+----+----+-----+\n",
      "|   A|   A|   1| true|\n",
      "|   B|   B|   2|false|\n",
      "|   C|null|   3| null|\n",
      "|null|   D|null| true|\n",
      "+----+----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_a.join(df_b, df_a['X1'] == df_b['X1'], 'outer')\\\n",
    ".select(df_a['X1'].alias('X1-a'),df_b['X1'].alias('X1-b'),'X2','X3').show() # same as 'full' or 'fullouter'\n",
    "# Spark doesn't merge the key columns and so need to alias the column names to distinguih between the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---+-----+\n",
      "|X1-a|X1-b| X2|   X3|\n",
      "+----+----+---+-----+\n",
      "|   A|   A|  1| true|\n",
      "|   B|   B|  2|false|\n",
      "|   C|null|  3| null|\n",
      "+----+----+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_a.join(df_b, df_a['X1'] == df_b['X1'], 'left_outer')\\\n",
    ".select(df_a['X1'].alias('X1-a'),df_b['X1'].alias('X1-b'),'X2','X3').show() # same as 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+-----+\n",
      "|X1-a|X1-b|  X2|   X3|\n",
      "+----+----+----+-----+\n",
      "|   A|   A|   1| true|\n",
      "|   B|   B|   2|false|\n",
      "|null|   D|null| true|\n",
      "+----+----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_a.join(df_b, df_a['X1'] == df_b['X1'], 'right_outer')\\\n",
    ".select(df_a['X1'].alias('X1-a'),df_b['X1'].alias('X1-b'),'X2','X3').show() # same as 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+-----+\n",
      "|X1-a|X1-b|  X2|   X3|\n",
      "+----+----+----+-----+\n",
      "|   A|   A|   1| true|\n",
      "|   B|   B|   2|false|\n",
      "|null|   D|null| true|\n",
      "+----+----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_a.join(df_b, df_a['X1'] == df_b['X1'], 'right')\\\n",
    ".select(df_a['X1'].alias('X1-a'),df_b['X1'].alias('X1-b'),'X2','X3').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+-----+\n",
      "|X1-a|X1-b|  X2|   X3|\n",
      "+----+----+----+-----+\n",
      "|   A|   A|   1| true|\n",
      "|   B|   B|   2|false|\n",
      "|   C|null|   3| null|\n",
      "|null|   D|null| true|\n",
      "+----+----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_a.join(df_b, df_a['X1'] == df_b['X1'], 'full')\\\n",
    ".select(df_a['X1'].alias('X1-a'),df_b['X1'].alias('X1-b'),'X2','X3').show()# same as 'fullouter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| X1| X2|\n",
      "+---+---+\n",
      "|  A|  1|\n",
      "|  B|  2|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_a.join(df_b, df_a['X1'] == df_b['X1'], 'leftsemi').show() # same as semijoin\n",
    "#.select(df_a['X1'].alias('X1-a'),df_b['X1'].alias('X1-b'),'X2','X3').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| X1| X2|\n",
      "+---+---+\n",
      "|  C|  3|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#anti-join = df.subtract('leftsemi')\n",
    "df_a.subtract(df_a.join(df_b, df_a['X1'] == df_b['X1'], 'leftsemi')).show() \n",
    "#.select(df_a['X1'].alias('X1-a'),df_b['X1'].alias('X1-b'),'X2','X3').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c = [{\"X1\":\"A\",\"X2\":1},{\"X1\":\"B\",\"X2\":2},{\"X1\":\"C\",\"X2\":3}]\n",
    "d = [{\"X1\":\"A\",\"X2\":1},{\"X1\":\"B\",\"X2\":2},{\"X1\":\"D\",\"X2\":4}]\n",
    "df_c = sc.parallelize(c).toDF()\n",
    "df_d = sc.parallelize(d).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| X1| X2|\n",
      "+---+---+\n",
      "|  A|  1|\n",
      "|  B|  2|\n",
      "|  C|  3|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_c.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| X1| X2|\n",
      "+---+---+\n",
      "|  A|  1|\n",
      "|  B|  2|\n",
      "|  D|  4|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| X1| X2|\n",
      "+---+---+\n",
      "|  B|  2|\n",
      "|  A|  1|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_c.intersect(df_d).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| X1| X2|\n",
      "+---+---+\n",
      "|  C|  3|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_c.subtract(df_d).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| X1| X2|\n",
      "+---+---+\n",
      "|  D|  4|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_d.subtract(df_c).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = [{\"X1\":\"A\",\"X2\":1},{\"X1\":\"B\",\"X2\":2},{\"X1\":\"C\",\"X2\":3}]\n",
    "f = [{\"X1\":\"D\",\"X2\":4},{\"X1\":\"E\",\"X2\":5},{\"X1\":\"F\",\"X2\":6}]\n",
    "df_e = sc.parallelize(e).toDF()\n",
    "df_f = sc.parallelize(f).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| X1| X2|\n",
      "+---+---+\n",
      "|  A|  1|\n",
      "|  B|  2|\n",
      "|  C|  3|\n",
      "|  D|  4|\n",
      "|  E|  5|\n",
      "|  F|  6|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_e.unionAll(df_f).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df_a.join(df_b, df_a['X1'] == df_b['X1'], 'semijoin')\\\n",
    "# .select(df_a['X1'].alias('X1-a'),df_b['X1'].alias('X1-b'),'X2','X3').show()\n",
    "# Gives error Unsupported join type 'semijoin'.\n",
    "# Supported join types include: 'inner', 'outer', 'full', 'fullouter', 'leftouter', 'left', 'rightouter', \n",
    "# 'right', 'leftsemi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. DataFrame : Tables & SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SQL on tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| X1| X2|\n",
      "+---+---+\n",
      "|  A|  1|\n",
      "|  B|  2|\n",
      "|  C|  3|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_a.registerTempTable(\"tableA\")\n",
    "sqlContext.sql(\"select * from tableA\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| X1|   X3|\n",
      "+---+-----+\n",
      "|  A| true|\n",
      "|  B|false|\n",
      "|  D| true|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_b.registerTempTable(\"tableB\")\n",
    "sqlContext.sql(\"select * from tableB\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-----+\n",
      "| X1| X2| X1|   X3|\n",
      "+---+---+---+-----+\n",
      "|  A|  1|  A| true|\n",
      "|  B|  2|  B|false|\n",
      "+---+---+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"select * from tableA JOIN tableB on tableA.X1 = tableB.X1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+-----+\n",
      "| X1| X2|  X1|   X3|\n",
      "+---+---+----+-----+\n",
      "|  A|  1|   A| true|\n",
      "|  B|  2|   B|false|\n",
      "|  C|  3|null| null|\n",
      "+---+---+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"select * from tableA LEFT JOIN tableB on tableA.X1 = tableB.X1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+-----+\n",
      "|  X1|  X2|  X1|   X3|\n",
      "+----+----+----+-----+\n",
      "|   A|   1|   A| true|\n",
      "|   B|   2|   B|false|\n",
      "|   C|   3|null| null|\n",
      "|null|null|   D| true|\n",
      "+----+----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"select * from tableA FULL JOIN tableB on tableA.X1 = tableB.X1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### _That's All, Folks !_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
